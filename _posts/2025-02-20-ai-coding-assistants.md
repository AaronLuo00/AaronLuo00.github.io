---
layout: default
title: "What AI Coding Assistants Taught Me About Human-AI Collaboration"
date: 2025-02-20
author_profile: true
---

# What AI Coding Assistants Taught Me About Human-AI Collaboration

*February 20, 2025*

I recently spent a week building my academic website using AI-powered coding assistants. What started as a simple development task turned into an unexpected lesson about the dynamics of human-AI collaboration — one that directly connects to my research on clinical AI systems.

## The Surprise Wasn't the Code

The AI assistant could generate React components, write CSS, and implement features faster than I could type the requirements. That part was impressive but predictable. The real surprise was how quickly I started *trusting* its output without verification.

By day three, I'd stopped reading the generated code line by line. By day five, I was approving changes based on whether the output "looked right" in the browser. I'd developed exactly the kind of automation complacency that I study in clinical settings.

## The Parallel to Clinical AI

This experience maps directly onto a well-documented problem in healthcare: **automation bias**. When AI systems are competent most of the time, human operators gradually reduce their independent verification. The system works perfectly — until it doesn't, and no one catches the error.

In my coding context, the consequence of a missed bug is a broken website. In a clinical context, it could be a missed diagnosis.

## Lessons for System Design

The experience reinforced several principles I think about in my research:

1. **Trust calibration matters more than accuracy.** A 95% accurate system that users treat as 100% accurate is more dangerous than an 85% accurate system that users verify every time.

2. **Friction can be a feature.** The most usable system isn't always the safest. Strategic points of human verification — even when they slow things down — are essential for high-stakes applications.

3. **Self-awareness is hard.** I study automation bias professionally, and I still fell into it within a week. If domain experts aren't immune, we can't rely on training alone to solve this problem.

## The Takeaway

Every interaction with AI tools is a micro-experiment in human-AI collaboration. Paying attention to how your own behavior changes — how trust builds, how verification drops off, how cognitive shortcuts develop — is one of the most underrated ways to build intuition for designing better AI systems.

---

*This post grew out of a conversation with colleagues about the gap between studying human-AI interaction and experiencing it firsthand.*
